{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Kaggle Competition: A trial run w Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This is an initial run through a Kaggle competition using a well known data set - passenger information from the Titanic and who survived.\n",
    "\n",
    "The objective is to use machine learning to predict who would survive as a way of getting comfortable with how to submit entries to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Variable\tDefinition\tKey\n",
    "\n",
    "survival\tSurvival\t0 = No, 1 = Yes \n",
    "\n",
    "pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "sex\tSex\t\n",
    "Age\tAge in years\t\n",
    "sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "parch\t# of parents / children aboard the Titanic\t\n",
    "ticket\tTicket number\t\n",
    "fare\tPassenger fare\t\n",
    "cabin\tCabin number\t\n",
    "embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# signoid function, set as global lambda expression for use throughout\n",
    "sig = lambda x: 1./(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "train= pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save 'Survived' column into Y_train\n",
    "Y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge data sets for transformations, now that survived stripped out\n",
    "data = train.append(test)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop('index',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look at what we have\n",
    "The first thing we will do is take a look at the data types and how much data is missing (null data) from each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the signficant missing data (age and cabin),\n",
    "# an approach to impute the values will need to be explored.\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin data is missing for 77% of the data\n",
    "# leave this off the table for now, as no real measure to impute any useful information\n",
    "# possibly use other data sources to fill in gaps\n",
    "1014/1309."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Break down names by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary to classify titles into major categories\n",
    "titles = {  'Capt':        'Professional',\n",
    "            'Col':         'Professional',\n",
    "            'Major':       'Professional',\n",
    "            'Jonkheer':    'Royal',\n",
    "            'Don':         'Royal',\n",
    "            'Sir' :        'Royal',\n",
    "            'Dr':          'Professional',\n",
    "            'Rev':         'Professional',\n",
    "            'the Countess':'Royal',\n",
    "            'Dona':        'Royal',\n",
    "            'Mme':         'Mrs',\n",
    "            'Mlle':        'Miss',\n",
    "            'Ms':          'Mrs',\n",
    "            'Mr' :         'Mr',\n",
    "            'Mrs' :        'Mrs',\n",
    "            'Miss' :       'Miss',\n",
    "            'Master' :     'Master',\n",
    "            'Lady' :       'Royal'\n",
    "            }\n",
    "\n",
    "# Title is between first comman and next period (e.g. , Mr. )\n",
    "data['Title'] = data['Name'].map(lambda name:name.split(',')[1]\\\n",
    "                                 .split('.')[0].strip()).map(titles)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at median age by gender, class and title\n",
    "ages = data.groupby(['Sex','Pclass','Title'])\n",
    "ages.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing ages by groupong by gender, class and title\n",
    "data['Age'] = data.groupby(['Sex','Pclass','Title'])['Age'].transform(lambda x:\n",
    "                                                                x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Age imputed, leave cabin as is for now\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Engineering: Categorize by Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Family'] = data['Parch'] + data['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers don't sum completey because the passenger list is not complete\n",
    "data['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Family_cat'] = data['Family'].map(lambda s :\n",
    "                                    'alone' if s == 1 else 'small' if s < 5 else 'large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Family_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at major categories survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(3,2, figsize=(16,10))\n",
    "category = 'Survival by Gender, Age, Class'\n",
    "\n",
    "# set bin sizes to b the same\n",
    "binBoundaries = np.linspace(0,80,9)\n",
    "\n",
    "def details(j):\n",
    "    if j == 0:\n",
    "        pclass = 'First'\n",
    "    elif j == 1:\n",
    "        pclass = 'Second'\n",
    "    else:\n",
    "        pclass = 'Third'\n",
    "    # sets titles for each subplot\n",
    "    ax2[j][0].set_title('{0} Class # Survivors'.format(pclass))\n",
    "    ax2[j][1].set_title('{0} Class # Deaths'.format(pclass)) \n",
    "    # sets common scale on all charts\n",
    "    ax2[j][0].set_ylim(0,200)\n",
    "    ax2[j][1].set_ylim(0,200)\n",
    "    # turn on legends\n",
    "    ax2[i][0].legend()\n",
    "    ax2[j][1].legend()\n",
    "\n",
    "for i in range(0,3):\n",
    "    # survivors\n",
    "    ax2[i][0].hist([data[(data['Survived']==1)&(data['Pclass']==i+1)&\n",
    "                            (data['Sex']=='male')]['Age'], data[(data['Survived']==1)&\n",
    "                            (data['Pclass']==i+1)&(data['Sex']=='female')]['Age']],\n",
    "                             stacked=True, color = ['g','b'], bins = binBoundaries,\n",
    "                             label = ['Male','Female'], alpha = 0.6)   \n",
    "    # deaths\n",
    "    ax2[i][1].hist([data[(data['Survived']==0)&(data['Pclass']==i+1)&\n",
    "                            (data['Sex']=='male')]['Age'], data[(data['Survived']==0)&\n",
    "                            (data['Pclass']==i+1)&(data['Sex']=='female')]['Age']],\n",
    "                             stacked=True, color = ['g','b'], bins = binBoundaries,\n",
    "                             label = ['Male','Female'], alpha = 0.6)\n",
    "    # set graph lables/titles, etc\n",
    "    details(i)\n",
    "\n",
    "# font size for main title\n",
    "fig.suptitle(category, fontsize=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Creating Age Brackets/Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Age_cat'] = data['Age'].map(lambda a: '0-5' if a < 6 else '6-15' if a <16 else '16-25'\n",
    "                                    if a < 26 else '26-35' if a <36 else '36-45' if a < 46\n",
    "                                    else '46+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket Data\n",
    "Let's take a look at the ticket data to see how we may be able to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Ticket_num'] =\\\n",
    "    data['Ticket'].apply(lambda x: pd.Series(x.split()[-1]))\n",
    "data['tick_len'] = data['Ticket_num'].apply(lambda x: pd.Series(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Seaborn pairplot to get a quick view of relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data[['Fare','Survived','Age','Sex','Family','Pclass','tick_len']],\n",
    "             hue='Survived');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 zero fares, is this correct, or shoudl they be imputed?\n",
    "# looking at Titanic data, some passengers did not pay a fair, either comped or company\n",
    "# sponsored, so difficult to call how to treat this\n",
    "data[data['Fare']==0.0]['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distribution of ticket prices\n",
    "\n",
    "plt.hist([data[data['Pclass']==1]['Fare'],\n",
    "         data[data['Pclass']==2]['Fare'],\n",
    "         data[data['Pclass']==3]['Fare']],\n",
    "         stacked=True, color = ['g','b','y'], bins = 30,\n",
    "         label = ['1','2','3'], alpha = 0.6)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Ticket Price Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Fare_cat'] = data['Fare'].map(lambda f: '0-20' if f < 21 else '21-40' if f <41\n",
    "                                      else '41-60' if f < 61 else '61-80' if f <81\n",
    "                                      else '81-100' if f < 101 else '101+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to remove in prep for Classificaiton Model\n",
    "\n",
    "* Passenger ID\n",
    "* Name - we have extracted title\n",
    "* Age - we have put Age into categores 'Age_cat'\n",
    "* Ticket - have created 'tick_len'\n",
    "* Fare - have created 'Fare_cat'\n",
    "* Cabin - too much missing data\n",
    "* Family - have put into larger buckets in 'Family_cat'\n",
    "* Ticket_num - used to create 'tick_len'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change numbers to strings before get_dummies\n",
    "\n",
    "to_num_str = ['Pclass','SibSp','Parch','tick_len']\n",
    "\n",
    "for s in to_num_str:\n",
    "    data[s] = data[s].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['PassengerId','Name','Age','Ticket','Fare','Cabin','Family','Ticket_num',\n",
    "                  'Survived'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop one column from each set of dummy variables\n",
    "data = data.drop(['Pclass_1','Sex_male','SibSp_8','Parch_6','Embarked_S',\n",
    "                        'Title_Royal','Family_cat_large','Age_cat_46+','tick_len_1',\n",
    "                        'Fare_cat_101+'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slice data back into train/test\n",
    "# Y_train data already removed from data df\n",
    "\n",
    "X_train = data.ix[0:890]\n",
    "X_test = data.ix[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up data with survived as first column\n",
    "train = X_train\n",
    "train.insert(0, 'Survived', Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = train.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Survived as first column - to correspond to index[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Distribution Model\n",
    "\n",
    "The model contains 41 parameters as a type of logistic regression, so the model is set up as follows:\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "$$g(x) =\\omega_0 + \\omega_1param_1 + \\omega_2param_2 + ... \\omega_{41} param_{41}$$ \n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "$$p = \\sigma(g) = \\frac{1}{1+e^{-g}}$$\n",
    "\n",
    "So the pdf of the likelihood becomes: \n",
    "$$log(\\sigma(g)) = -log({1+e^{-g}})$$\n",
    "\n",
    "### Prior\n",
    "\n",
    "For the Prior $\\pi$ we chose the following over $\\omega_0,\\omega_1, \\omega_2, \\omega_3, ..., \\omega_{40}$:\n",
    "\n",
    "$$ \\pi(\\omega) = \\frac{1}{2 \\pi} e^{-\\frac{1}{2}\\omega_0^2}e^{-\\frac{1}{2}\\omega_1^2} e^{-\\frac{1}{2}\\omega_2^2} ... e^{-\\frac{1}{2}\\omega_{41}^2} $$\n",
    "\n",
    "the log prior is:\n",
    "\n",
    "$$ =  -\\frac{1}{2}(\\omega_0^2 + \\omega_1^2+ \\omega_2^2 +...+ \\omega_{41}^2) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints\n",
    "\n",
    "1. if status == 1 then return P\n",
    "2. if status == 0 then return 1-p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda g: 1./(1+np.exp(-g))\n",
    "\n",
    "def log_predictive(w,dd):\n",
    "    g = w[0] + np.sum([w[i]*dd[i] for i in range(1,40)])\n",
    "    if dd[0] == 1:\n",
    "        return np.log(sigmoid(g))\n",
    "    else:\n",
    "        return np.log(1 - sigmoid(g))\n",
    "\n",
    "def log_prior(w):\n",
    "    return -0.5 * np.sum([i**2 for i in w]) \n",
    "\n",
    "def lnprob(w):\n",
    "    return log_prior(w) + np.sum([log_predictive(w,d) for d in train_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import emcee\n",
    "import corner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer() # to time how long code takes to run\n",
    "\n",
    "\n",
    "# Run MCMC \n",
    "\n",
    "steps = 1000 # number of steps\n",
    "\n",
    "nwalkers = 100\n",
    "ndim = 41 # reduced by two variables (remove 1 each from sets of dummy variables)\n",
    "p0 = np.random.rand(nwalkers*ndim).reshape((nwalkers,ndim))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, threads = 75)\n",
    "pos, prob, state = sampler.run_mcmc(p0, 100)\n",
    "sampler.reset()\n",
    "pos, prob, state = sampler.run_mcmc(pos, steps)\n",
    "samples = sampler.flatchain\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time \n",
    "\n",
    "print('Elapsed time for MCMCM run: {0}'.format(elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "MC_samples = pd.DataFrame(samples)\n",
    "MC_samples.to_csv('MC_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LC project to set how to run test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of Test Set: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
